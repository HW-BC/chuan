{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 实现CO2排量预测\n",
    "## 导入所需的库"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:43:27.968820Z",
     "start_time": "2024-07-16T11:43:27.963804Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from scipy.stats import yeojohnson, yeojohnson_normmax, yeojohnson_llf\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PowerTransformer"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "### 构造滑动窗口数据集"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:43:27.999064Z",
     "start_time": "2024-07-16T11:43:27.992031Z"
    }
   },
   "source": [
    "def create_sequencesCO2(window): \n",
    "    data = pd.read_csv('D:\\Pycharm\\chuan\\data3.csv', encoding='gbk')\n",
    "    # data = data['CO2排放总量']\n",
    "    pt = PowerTransformer(method='yeo-johnson')\n",
    "    data = pt.fit_transform(data['CO2排放总量'].values.reshape(-1, 1)) # 进行Yeo-Johnson变换\n",
    "    sequences = [] \n",
    "    targets = [] \n",
    "    for i in range(len(data) - window):\n",
    "        # window为3：seq：[1,2,3]\n",
    "        seq = data[i:i + window] \n",
    "        target = data[i + window]\n",
    "        # sequences:[[1,2,3],[]]\n",
    "        sequences.append(seq) \n",
    "        targets.append(target)\n",
    "    # 将numpy数组转换为PyTorch张量.x：（[[1,2,3],[]]）\n",
    "    x=np.array(sequences)\n",
    "    y=np.array(targets)\n",
    "    print(x.shape,y.shape)\n",
    "    print(x,y)\n",
    "    return x, y, pt"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:43:28.016624Z",
     "start_time": "2024-07-16T11:43:28.011039Z"
    }
   },
   "source": [
    "class EmissionsDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.features = x\n",
    "        self.targets = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 从数据集中获取单个样本的特征和目标，并将它们转换为 PyTorch 张量（Tensor）的格式，\n",
    "        # 并添加一个维度作为批处理维度。\n",
    "        # 特征：前几日排放量\n",
    "        # 标签：后一天的CO2排放总量\n",
    "        feature = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        target = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "        return feature, target"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络\n",
    "### RNN GRU LSTM FC"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:43:28.037524Z",
     "start_time": "2024-07-16T11:43:28.018630Z"
    }
   },
   "source": [
    "class RNNModel(nn.Module):\n",
    "    # 定义RNN模型\n",
    "    # hidden_dim：隐藏层维度\n",
    "    # num_layers：RNN层数\n",
    "    # input_dim：输入维度\n",
    "    # output_dim：输出维度\n",
    "    def __init__(self, hidden_dim=64, num_layers=2, input_dim=1, output_dim=1):\n",
    "        super(RNNModel, self).__init__()\n",
    "        # batch_first=True 表示输入数据的形状为 [batch_size, sequence_length, input_dim]\n",
    "        # batch_size: 批处理大小，即一次处理的数据数量\n",
    "        # sequence_length: 序列长度，即每个输入样本的长度,特征数量（NH3与CO2的排放量作为输入特征预测明天CO2排放量）= 2\n",
    "        # input_dim: 输入维度，(今天的NH3排放量=1（size=1），昨天和今天的CO2排放量（size=2）)\n",
    "        # shape:\n",
    "        # [\n",
    "        ##     [[8],[9,10]],\n",
    "        #     [[2],[8,2]],\n",
    "        #     [[3],[3,4]],\n",
    "        # ]\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        # 全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.rnn.num_layers, x.size(0), self.rnn.hidden_size).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, num_layers=2, input_dim=1, output_dim=1):\n",
    "        super(GRUModel, self).__init__()\n",
    "        # GRU层\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        # 创建一个多头注意力层，输入的特征维度为 hidden_dim，使用2个注意力头\n",
    "        self.attention = nn.MultiheadAttention(hidden_dim, num_heads=2)\n",
    "        # 层归一化层\n",
    "        self.ln = nn.LayerNorm(hidden_dim)\n",
    "        # 前馈神经网络，包括两层线性变换和一个ReLU激活函数\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, hidden_dim)\n",
    "        )\n",
    "        # 线性层，用于将隐藏状态映射到输出维度\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始化 GRU 隐藏状态h0,大小为 (num_layers, batch_size, hidden_dim)，并将其移动到输入 x 的设备上（CPU或GPU）\n",
    "        h0 = torch.zeros(self.gru.num_layers, x.size(0), self.gru.hidden_size).to(x.device)\n",
    "        # 通过GRU层：将输入 x 和初始隐藏状态 h0 传入GRU层，输出 out 是GRU的输出，第二个返回值是最后一个隐藏状态（在这里未使用）\n",
    "        out, _ = self.gru(x, h0)\n",
    "        # 将输出 out 传入注意力层，得到注意力加权后的输出 at_out 和注意力权重\n",
    "        # at_out, _ = self.attention(out, out, out)\n",
    "        # 将注意力加权后的输出与原始输出相加（残差连接），并进行层归一化\n",
    "        # out = self.ln(out + at_out)\n",
    "        # 将归一化后的输出传入前馈神经网络\n",
    "        # out = self.ffn(out)\n",
    "        # 将前馈神经网络的输出传入线性层，得到最终的输出\n",
    "        # out = self.ln(out + at_out)\n",
    "        # 提取最后一个时间步的输出 out[:, -1, :]，并通过全连接层得到最终输出\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, num_layers=2, input_dim=1, output_dim=1, bidirectional=False):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        # 防止过拟合\n",
    "        # self.fc = nn.Sequential(nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, 32), nn.ReLU(),nn.Linear(32, output_dim))\n",
    "        # self.batchnorm = nn.BatchNorm1d(hidden_dim * 2 if bidirectional else hidden_dim)\n",
    "        # self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 初始化 LSTM 隐藏状态\n",
    "        h0 = torch.zeros(self.num_layers * (2 if self.bidirectional else 1), x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers * (2 if self.bidirectional else 1), x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # LSTM 前向传播\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # 取最后一个时间步的输出，并送入全连接层\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        # 防止过拟合\n",
    "        # out = self.dropout(self.batchnorm(out[:, -1, :]))\n",
    "        # out = self.fc(out)\n",
    "        # return out\n",
    "        return out\n",
    "\n",
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, input_dim=1, output_dim=1, is_linear=False, window=1):\n",
    "        super(FullyConnected, self).__init__()\n",
    "        self.is_linear = is_linear\n",
    "        self.window = window\n",
    "        # 全连接层（线性层、激活层、线性层）\n",
    "        self.fc1 = nn.Linear(input_dim * window, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        # 单线性层\n",
    "        self.only = nn.Linear(input_dim * window, output_dim)\n",
    "    def forward(self, x):\n",
    "        if self.is_linear:\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.only(x)\n",
    "        else:\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.fc1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.fc2(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:43:28.070808Z",
     "start_time": "2024-07-16T11:43:28.054848Z"
    }
   },
   "source": [
    "import os\n",
    "import uuid\n",
    "import glob\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, \n",
    "                 patience: int = 100,\n",
    "                 min_delta: float = 0.00, \n",
    "                 path: str = None, \n",
    "                 monitor: str = 'val_loss', \n",
    "                 mode: str = 'min', \n",
    "                 save_top_k: int = 1,\n",
    "                 dataset_name: str = None,\n",
    "                 save_model: bool = False\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How many epochs to wait after last time validation loss improved.\n",
    "            min_delta (float): Minimum change in the monitored quantity to qualify as an improvement.设置监控某个参数更新的最小值\n",
    "            path (str): Path to save the best model.\n",
    "            monitor (str): Quantity to be monitored. Default is 'val_loss'.\n",
    "            mode (str): One of {'min', 'max'}. In 'min' mode, training will stop when the quantity monitored has stopped decreasing.（设为min：val_loss不减小时，停止训练）      \n",
    "            save_top_k (int): Number of best models to save. Default is 1.\n",
    "            dataset_name (str): Name of the dataset. Default is None.\n",
    "            save_model (bool): Whether to save the model. Default is False.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        # 更新参数时的最小要求值\n",
    "        self.min_delta = min_delta\n",
    "        # 存储某个指标的最佳值（根据mode初始化为正负无穷）\n",
    "        self.best_metrics = [float('inf')] if mode == 'min' else [float('-inf')]\n",
    "        # 计算早停轮次\n",
    "        self.counter = 0\n",
    "        # 早停标志\n",
    "        self.early_stop = False\n",
    "        self.dataset_name = dataset_name\n",
    "        # 监测指标\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        # 保存的模型数量\n",
    "        self.save_top_k = save_top_k\n",
    "        # 定义更新的规则\n",
    "        self.is_better = None\n",
    "        self.sym = False\n",
    "        self.save_model = save_model\n",
    "        self.run_id = str(uuid.uuid4())  # Unique identifier for the training run\n",
    "\n",
    "        # 最优模型地址\n",
    "        if path:\n",
    "            self.path = path\n",
    "            self.sym = False\n",
    "        else:\n",
    "            self.path = None\n",
    "\n",
    "        # 定义更新的规则\n",
    "        if self.mode == 'min':\n",
    "            self.is_better = lambda a, best: a < best\n",
    "        elif self.mode == 'max':\n",
    "            self.is_better = lambda a, best: a > best\n",
    "        else:\n",
    "            raise ValueError(f'Unknown mode: {self.mode}')\n",
    "    \n",
    "    # model：模型参数\n",
    "    def __call__(self, val_metric, model):\n",
    "        # 如果验证集损失小于当前最优\n",
    "        if self.is_better(val_metric, self.best_metrics[-1] - self.min_delta):\n",
    "            # 保存最佳\n",
    "            self.best_metrics.append(val_metric)\n",
    "            if self.save_model:\n",
    "                self.save_checkpoint(model)\n",
    "            print(f\"{self.monitor} improved to {val_metric:.4f}\")\n",
    "            # 删除记录的非最优模型，重置计数器\n",
    "            self._cleanup_checkpoints()\n",
    "            self.counter = 0 \n",
    "        else:\n",
    "            # 如果验证集损失没有改善，则增加计数器\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        \n",
    "        # 选出当前最优\n",
    "        best_metric = min(self.best_metrics) if self.mode == 'min' else max(self.best_metrics)\n",
    "        print(f\"Current best {self.monitor}: {best_metric:.4f}\")\n",
    "        #     达瓦\n",
    "    def add_path(self):\n",
    "        if self.path is None:\n",
    "            # monitor：验证损失。best_metrics[-1]：最后一个（最优）验证损失值。run_id：标识\n",
    "            self.path = f'./pytorch_checkpoints/co2/{self.monitor}-{self.best_metrics[-1]:.4f}-{self.run_id}.pth'\n",
    "            self.sym = True\n",
    "        if self.sym:\n",
    "            self.path = f'./pytorch_checkpoints/co2/{self.monitor}-{self.best_metrics[-1]:.4f}-{self.run_id}.pth'\n",
    "        os.makedirs(os.path.dirname(self.path), exist_ok=True)\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        \"\"\"Saves model when monitored metric improves.\"\"\"\n",
    "        self.add_path()\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "\n",
    "    # 清除非最优模型\n",
    "    def _cleanup_checkpoints(self):\n",
    "        \"\"\"Deletes all but the top k models for the current run instance.\"\"\"\n",
    "        # 查找当前目录下（./pytorch_checkpoints/co2/）所有符合特定模式的文件名。\n",
    "        checkpoints = glob.glob(f'./pytorch_checkpoints/co2/{self.monitor}-*-{self.run_id}.pth')\n",
    "        # 按照修改时间排序\n",
    "        checkpoints.sort(key=os.path.getmtime)\n",
    "        # 保留最新的k个文件，其余删除\n",
    "        if len(checkpoints) > self.save_top_k:\n",
    "            for ckpt in checkpoints[:-self.save_top_k]:\n",
    "                os.remove(ckpt)\n",
    "\n",
    "    def load_checkpoint(self, model):\n",
    "        \"\"\"Loads the saved model.\"\"\"\n",
    "        model.load_state_dict(torch.load(self.path))"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义超参数"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:43:28.090202Z",
     "start_time": "2024-07-16T11:43:28.078307Z"
    }
   },
   "source": [
    "import argparse\n",
    "# python CO2_emissions.py --init_seed 42 --batch_size 64 --hidden_dim 128 --lr 1e-1 --num_layers 2 --num_heads 2 --max_epochs 50 --data_path \"D:\\Pycharm\\chuan\\data.csv\"\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Carbon dioxide emissions with PyTorch Lightning')\n",
    "parser.add_argument('--init_seed', type=int, default=42, help='Seed for initializing random number generators')\n",
    "parser.add_argument('--batch_size', type=int, default=16, help='Batch size for training and evaluation')\n",
    "parser.add_argument('--input_dim', type=int, default=1, help='Dimensionality of input features')\n",
    "parser.add_argument('--hidden_dim', type=int, default=128, help='Dimensionality of hidden layers in RNN')\n",
    "parser.add_argument('--lr', type=float, default=1e-3, help='Learning Rate for training the model')\n",
    "parser.add_argument('--num_layers', type=int, default=2, help='Number of RNN layers')\n",
    "parser.add_argument('--num_heads', type=int, default=2, help='Number of attention heads in Multi-Head Attention')\n",
    "parser.add_argument('--max_epochs', type=int, default=100, help='Maximum number of epochs to train the model')\n",
    "parser.add_argument('--data_path', type=str, default='D:\\Pycharm\\chuan\\data3.csv', help='Path to the CSV data file')\n",
    "# parser.add_argument('--data_path', type=str, default='D:\\Pycharm\\chuan\\dataset\\Video1.csv', help='Path to the CSV data file')\n",
    "parser.add_argument('--patience', type=int, default=80, help='Patience for early stopping')\n",
    "parser.add_argument('--num_workers', type=int, default=0, help='Number of workers for data loading')\n",
    "parser.add_argument('--model_type', type=str, default='RNN', choices=['RNN', 'GRU', 'LSTM', 'FC'], help='Type of model to use')\n",
    "parser.add_argument('--bidirectional', type=bool, default=True, help='Whether to use a bidirectional LSTM')\n",
    "parser.add_argument('--window', type=int, default=4, help='The number of features')\n",
    "parser.add_argument('--is_linear', type=bool, default=True, help='是否单线性层')\n",
    "hparams, unknown = parser.parse_known_args()"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:43:29.260272Z",
     "start_time": "2024-07-16T11:43:28.097200Z"
    }
   },
   "source": [
    "from rich.console import Console\n",
    "from rich.text import Text\n",
    "from rich.table import Table\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "init_seed = hparams.init_seed\n",
    "torch.manual_seed(init_seed)\n",
    "torch.cuda.manual_seed(init_seed)\n",
    "torch.cuda.manual_seed_all(init_seed)\n",
    "np.random.seed(init_seed)  # 用于numpy的随机数\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "x, y, pt = create_sequencesCO2(hparams.window)\n",
    "\n",
    "if hparams.model_type == 'RNN':\n",
    "    model = RNNModel(input_dim=hparams.input_dim, hidden_dim=hparams.hidden_dim, num_layers=hparams.num_layers)\n",
    "elif hparams.model_type == 'GRU':\n",
    "    model = GRUModel(input_dim=hparams.input_dim, hidden_dim=hparams.hidden_dim, num_layers=hparams.num_layers)\n",
    "elif hparams.model_type == 'LSTM':\n",
    "    model = LSTMModel(input_dim=hparams.input_dim, hidden_dim=hparams.hidden_dim, num_layers=hparams.num_layers, bidirectional = hparams.bidirectional)\n",
    "elif hparams.model_type == 'FC':\n",
    "    model = FullyConnected(input_dim=hparams.input_dim, hidden_dim=hparams.hidden_dim, is_linear=hparams.is_linear, window = hparams.window)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown model type: {hparams.model_type}\")\n",
    "\n",
    "model.to(device)\n",
    "# 实例化数据集\n",
    "dataset = EmissionsDataset(x, y)\n",
    "# 划分数据集\n",
    "train_val_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=hparams.init_seed)\n",
    "train_dataset, val_dataset = train_test_split(train_val_dataset, test_size=0.2, random_state=hparams.init_seed)\n",
    "\n",
    "# 实例化数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=hparams.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=hparams.batch_size, shuffle=False)\n",
    "\n",
    "# 实例化优化器和损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hparams.lr)\n",
    "# 损失函数：\n",
    "# MAE：nn.L1Loss()\n",
    "# MSE：nn.MSELoss()\n",
    "# 交叉熵：nn.CrossEntropyLoss()\n",
    "criterion = nn.L1Loss()\n",
    "early_stopping = EarlyStopping(patience=hparams.patience, save_model=True)\n",
    "\n",
    "# 简单早停：\n",
    "# patience = 5\n",
    "# counter = 0\n",
    "# best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(hparams.max_epochs):\n",
    "    train_losses = []\n",
    "    # 进入训练模式\n",
    "    model.train()\n",
    "    # 循环训练集数据加载器中的每个batch，将inputs、targets加载到模型中训练\n",
    "    for batch in train_loader:\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        # 算出预测值\n",
    "        pred = model(inputs)\n",
    "        # 计算损失\n",
    "        loss = criterion(pred, targets)\n",
    "        # 清零梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 更新参数\n",
    "        optimizer.step()\n",
    "        # 记录每一个batch的损失\n",
    "        train_losses.append(loss)\n",
    "\n",
    "    # 计算一个epoch的平均损失\n",
    "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "\n",
    "    # 在验证集上计算损失\n",
    "    val_losses = []\n",
    "    # 进入评估模式\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            pred = model(inputs)\n",
    "            loss = criterion(pred, targets)\n",
    "            val_losses.append(loss)\n",
    "\n",
    "    avg_val_loss = sum(val_losses) / len(val_losses)\n",
    "\n",
    "    # 检查是否需要提前停止\n",
    "    early_stopping(avg_val_loss, model)\n",
    "    \n",
    "    # 简单的早停：\n",
    "    # if avg_val_loss < best_val_loss:\n",
    "    #     best_val_loss = avg_val_loss\n",
    "    #     counter = 0\n",
    "    # else:     # 如果验证损失没有改善，增加计数器\n",
    "    #     counter += 1\n",
    "        \n",
    "    # 打印训练和验证损失\n",
    "    print('Epoch: [{epoch}][{num_epochs}]\\t'\n",
    "        'Loss {avg_train_loss:.4f}\\t'\n",
    "        'val_Loss {avg_val_loss:.4f}\\n'.format(\n",
    "        epoch=epoch + 1, num_epochs=hparams.max_epochs,\n",
    "        avg_train_loss=avg_train_loss,\n",
    "        avg_val_loss=avg_val_loss)\n",
    "    )\n",
    "    \n",
    "    # 简单早停\n",
    "    # if counter >= patience:\n",
    "    #     print(\"Early stopping\")\n",
    "    #     break\n",
    "        \n",
    "    if early_stopping.early_stop:\n",
    "        if epoch == hparams.max_epochs:\n",
    "            print(\"max epoch reached\")\n",
    "        else:\n",
    "            print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "if early_stopping.save_model:\n",
    "    early_stopping.load_checkpoint(model)\n",
    "\n",
    "# 测试模型\n",
    "test_losses = []\n",
    "test_loader = DataLoader(test_dataset, batch_size=hparams.batch_size, shuffle=False)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        # 算出预测值\n",
    "        pred = model(inputs)\n",
    "        orig_pred = pt.inverse_transform(pred.cpu().numpy().reshape(-1, 1))\n",
    "        orig_targets = pt.inverse_transform(targets.cpu().numpy().reshape(-1, 1))\n",
    "        test_mae = mean_absolute_error(orig_pred, orig_targets)\n",
    "        test_r2 = r2_score(orig_targets, orig_pred)\n",
    "        test_losses.append(test_mae)\n",
    "\n",
    "avg_test_loss = sum(test_losses) / len(test_losses)\n",
    "\n",
    "print('-' * 100)\n",
    "console = Console()\n",
    "table = Table(title=\"Test Results\")\n",
    "table.add_column(\"Metrics\", style=\"cyan\")\n",
    "table.add_column(\"Results\", style=\"magenta\")\n",
    "table.add_row('test_mae', f\"{avg_test_loss:.4f}\")\n",
    "table.add_row('test_r2', f\"{test_r2:.4f}\")\n",
    "\n",
    "console.print(table)\n",
    "print('test_mae', f\"{avg_test_loss:.4f}\")\n",
    "print('test_r2', f\"{test_r2:.4f}\")\n",
    "test_losses.clear()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 4, 1) (28, 1)\n",
      "[[[-1.88139381]\n",
      "  [-0.15846261]\n",
      "  [ 0.11676888]\n",
      "  [-0.23812704]]\n",
      "\n",
      " [[-0.15846261]\n",
      "  [ 0.11676888]\n",
      "  [-0.23812704]\n",
      "  [ 0.42940496]]\n",
      "\n",
      " [[ 0.11676888]\n",
      "  [-0.23812704]\n",
      "  [ 0.42940496]\n",
      "  [ 0.15484801]]\n",
      "\n",
      " [[-0.23812704]\n",
      "  [ 0.42940496]\n",
      "  [ 0.15484801]\n",
      "  [ 0.11994289]]\n",
      "\n",
      " [[ 0.42940496]\n",
      "  [ 0.15484801]\n",
      "  [ 0.11994289]\n",
      "  [-0.53250898]]\n",
      "\n",
      " [[ 0.15484801]\n",
      "  [ 0.11994289]\n",
      "  [-0.53250898]\n",
      "  [-0.46828704]]\n",
      "\n",
      " [[ 0.11994289]\n",
      "  [-0.53250898]\n",
      "  [-0.46828704]\n",
      "  [-1.45531381]]\n",
      "\n",
      " [[-0.53250898]\n",
      "  [-0.46828704]\n",
      "  [-1.45531381]\n",
      "  [-1.18394154]]\n",
      "\n",
      " [[-0.46828704]\n",
      "  [-1.45531381]\n",
      "  [-1.18394154]\n",
      "  [-1.62624807]]\n",
      "\n",
      " [[-1.45531381]\n",
      "  [-1.18394154]\n",
      "  [-1.62624807]\n",
      "  [-1.2836217 ]]\n",
      "\n",
      " [[-1.18394154]\n",
      "  [-1.62624807]\n",
      "  [-1.2836217 ]\n",
      "  [-1.18481239]]\n",
      "\n",
      " [[-1.62624807]\n",
      "  [-1.2836217 ]\n",
      "  [-1.18481239]\n",
      "  [-1.4993197 ]]\n",
      "\n",
      " [[-1.2836217 ]\n",
      "  [-1.18481239]\n",
      "  [-1.4993197 ]\n",
      "  [-1.06998365]]\n",
      "\n",
      " [[-1.18481239]\n",
      "  [-1.4993197 ]\n",
      "  [-1.06998365]\n",
      "  [-0.0548754 ]]\n",
      "\n",
      " [[-1.4993197 ]\n",
      "  [-1.06998365]\n",
      "  [-0.0548754 ]\n",
      "  [ 0.49620795]]\n",
      "\n",
      " [[-1.06998365]\n",
      "  [-0.0548754 ]\n",
      "  [ 0.49620795]\n",
      "  [ 0.70338856]]\n",
      "\n",
      " [[-0.0548754 ]\n",
      "  [ 0.49620795]\n",
      "  [ 0.70338856]\n",
      "  [ 0.46238548]]\n",
      "\n",
      " [[ 0.49620795]\n",
      "  [ 0.70338856]\n",
      "  [ 0.46238548]\n",
      "  [ 0.325301  ]]\n",
      "\n",
      " [[ 0.70338856]\n",
      "  [ 0.46238548]\n",
      "  [ 0.325301  ]\n",
      "  [ 0.72802413]]\n",
      "\n",
      " [[ 0.46238548]\n",
      "  [ 0.325301  ]\n",
      "  [ 0.72802413]\n",
      "  [ 0.01320635]]\n",
      "\n",
      " [[ 0.325301  ]\n",
      "  [ 0.72802413]\n",
      "  [ 0.01320635]\n",
      "  [-0.00256921]]\n",
      "\n",
      " [[ 0.72802413]\n",
      "  [ 0.01320635]\n",
      "  [-0.00256921]\n",
      "  [ 0.72940466]]\n",
      "\n",
      " [[ 0.01320635]\n",
      "  [-0.00256921]\n",
      "  [ 0.72940466]\n",
      "  [ 0.71680355]]\n",
      "\n",
      " [[-0.00256921]\n",
      "  [ 0.72940466]\n",
      "  [ 0.71680355]\n",
      "  [ 1.40784966]]\n",
      "\n",
      " [[ 0.72940466]\n",
      "  [ 0.71680355]\n",
      "  [ 1.40784966]\n",
      "  [ 1.61778453]]\n",
      "\n",
      " [[ 0.71680355]\n",
      "  [ 1.40784966]\n",
      "  [ 1.61778453]\n",
      "  [ 1.57282185]]\n",
      "\n",
      " [[ 1.40784966]\n",
      "  [ 1.61778453]\n",
      "  [ 1.57282185]\n",
      "  [ 1.84682894]]\n",
      "\n",
      " [[ 1.61778453]\n",
      "  [ 1.57282185]\n",
      "  [ 1.84682894]\n",
      "  [ 1.37028907]]] [[ 0.42940496]\n",
      " [ 0.15484801]\n",
      " [ 0.11994289]\n",
      " [-0.53250898]\n",
      " [-0.46828704]\n",
      " [-1.45531381]\n",
      " [-1.18394154]\n",
      " [-1.62624807]\n",
      " [-1.2836217 ]\n",
      " [-1.18481239]\n",
      " [-1.4993197 ]\n",
      " [-1.06998365]\n",
      " [-0.0548754 ]\n",
      " [ 0.49620795]\n",
      " [ 0.70338856]\n",
      " [ 0.46238548]\n",
      " [ 0.325301  ]\n",
      " [ 0.72802413]\n",
      " [ 0.01320635]\n",
      " [-0.00256921]\n",
      " [ 0.72940466]\n",
      " [ 0.71680355]\n",
      " [ 1.40784966]\n",
      " [ 1.61778453]\n",
      " [ 1.57282185]\n",
      " [ 1.84682894]\n",
      " [ 1.37028907]\n",
      " [-0.17179549]]\n",
      "val_loss improved to 0.7354\n",
      "Current best val_loss: 0.7354\n",
      "Epoch: [1][100]\tLoss 1.1565\tval_Loss 0.7354\n",
      "\n",
      "val_loss improved to 0.7219\n",
      "Current best val_loss: 0.7219\n",
      "Epoch: [2][100]\tLoss 1.0014\tval_Loss 0.7219\n",
      "\n",
      "Current best val_loss: 0.7219\n",
      "Epoch: [3][100]\tLoss 0.4418\tval_Loss 0.7229\n",
      "\n",
      "val_loss improved to 0.7066\n",
      "Current best val_loss: 0.7066\n",
      "Epoch: [4][100]\tLoss 1.0569\tval_Loss 0.7066\n",
      "\n",
      "val_loss improved to 0.6954\n",
      "Current best val_loss: 0.6954\n",
      "Epoch: [5][100]\tLoss 1.0874\tval_Loss 0.6954\n",
      "\n",
      "val_loss improved to 0.6943\n",
      "Current best val_loss: 0.6943\n",
      "Epoch: [6][100]\tLoss 0.9850\tval_Loss 0.6943\n",
      "\n",
      "Current best val_loss: 0.6943\n",
      "Epoch: [7][100]\tLoss 0.7353\tval_Loss 0.7142\n",
      "\n",
      "Current best val_loss: 0.6943\n",
      "Epoch: [8][100]\tLoss 0.4462\tval_Loss 0.7165\n",
      "\n",
      "val_loss improved to 0.6405\n",
      "Current best val_loss: 0.6405\n",
      "Epoch: [9][100]\tLoss 0.7450\tval_Loss 0.6405\n",
      "\n",
      "val_loss improved to 0.6351\n",
      "Current best val_loss: 0.6351\n",
      "Epoch: [10][100]\tLoss 0.6485\tval_Loss 0.6351\n",
      "\n",
      "Current best val_loss: 0.6351\n",
      "Epoch: [11][100]\tLoss 0.4186\tval_Loss 0.6962\n",
      "\n",
      "Current best val_loss: 0.6351\n",
      "Epoch: [12][100]\tLoss 0.6243\tval_Loss 0.7663\n",
      "\n",
      "Current best val_loss: 0.6351\n",
      "Epoch: [13][100]\tLoss 0.5471\tval_Loss 0.7934\n",
      "\n",
      "Current best val_loss: 0.6351\n",
      "Epoch: [14][100]\tLoss 0.3961\tval_Loss 0.8361\n",
      "\n",
      "Current best val_loss: 0.6351\n",
      "Epoch: [15][100]\tLoss 0.4507\tval_Loss 0.7679\n",
      "\n",
      "val_loss improved to 0.5608\n",
      "Current best val_loss: 0.5608\n",
      "Epoch: [16][100]\tLoss 0.3447\tval_Loss 0.5608\n",
      "\n",
      "val_loss improved to 0.5189\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [17][100]\tLoss 0.6967\tval_Loss 0.5189\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [18][100]\tLoss 0.8873\tval_Loss 0.5213\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [19][100]\tLoss 0.9327\tval_Loss 0.5468\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [20][100]\tLoss 0.4882\tval_Loss 0.5920\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [21][100]\tLoss 0.2706\tval_Loss 0.6335\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [22][100]\tLoss 0.3725\tval_Loss 0.7418\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [23][100]\tLoss 0.2591\tval_Loss 0.8360\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [24][100]\tLoss 0.3421\tval_Loss 0.8575\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [25][100]\tLoss 0.2696\tval_Loss 0.8515\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [26][100]\tLoss 0.5530\tval_Loss 0.8226\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [27][100]\tLoss 0.3154\tval_Loss 0.7622\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [28][100]\tLoss 0.3000\tval_Loss 0.7134\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [29][100]\tLoss 0.3312\tval_Loss 0.6810\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [30][100]\tLoss 0.3877\tval_Loss 0.6522\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [31][100]\tLoss 0.3710\tval_Loss 0.6487\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [32][100]\tLoss 0.6646\tval_Loss 0.6234\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [33][100]\tLoss 0.3155\tval_Loss 0.5993\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [34][100]\tLoss 0.3408\tval_Loss 0.5892\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [35][100]\tLoss 0.5313\tval_Loss 0.5833\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [36][100]\tLoss 0.2761\tval_Loss 0.5829\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [37][100]\tLoss 0.4948\tval_Loss 0.5885\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [38][100]\tLoss 0.2759\tval_Loss 0.5906\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [39][100]\tLoss 0.4134\tval_Loss 0.5867\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [40][100]\tLoss 0.4897\tval_Loss 0.6003\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [41][100]\tLoss 0.2460\tval_Loss 0.6140\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [42][100]\tLoss 0.1833\tval_Loss 0.6116\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [43][100]\tLoss 0.2682\tval_Loss 0.5999\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [44][100]\tLoss 0.1902\tval_Loss 0.5890\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [45][100]\tLoss 0.2102\tval_Loss 0.5858\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [46][100]\tLoss 0.3108\tval_Loss 0.5891\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [47][100]\tLoss 0.4434\tval_Loss 0.5870\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [48][100]\tLoss 0.5350\tval_Loss 0.5726\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [49][100]\tLoss 0.3555\tval_Loss 0.5581\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [50][100]\tLoss 0.2860\tval_Loss 0.5465\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [51][100]\tLoss 0.3261\tval_Loss 0.5442\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [52][100]\tLoss 0.5492\tval_Loss 0.5507\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [53][100]\tLoss 0.3694\tval_Loss 0.5582\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [54][100]\tLoss 0.2889\tval_Loss 0.5612\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [55][100]\tLoss 0.3448\tval_Loss 0.5750\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [56][100]\tLoss 0.2929\tval_Loss 0.5881\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [57][100]\tLoss 0.3391\tval_Loss 0.5987\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [58][100]\tLoss 0.1965\tval_Loss 0.6251\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [59][100]\tLoss 0.2126\tval_Loss 0.6528\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [60][100]\tLoss 0.3672\tval_Loss 0.6575\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [61][100]\tLoss 0.3332\tval_Loss 0.6401\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [62][100]\tLoss 0.2244\tval_Loss 0.6047\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [63][100]\tLoss 0.3573\tval_Loss 0.5760\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [64][100]\tLoss 0.5282\tval_Loss 0.5864\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [65][100]\tLoss 0.3113\tval_Loss 0.5955\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [66][100]\tLoss 0.3200\tval_Loss 0.5931\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [67][100]\tLoss 0.4450\tval_Loss 0.5814\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [68][100]\tLoss 0.1706\tval_Loss 0.5996\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [69][100]\tLoss 0.2697\tval_Loss 0.6319\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [70][100]\tLoss 0.4385\tval_Loss 0.6498\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [71][100]\tLoss 0.2227\tval_Loss 0.6534\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [72][100]\tLoss 0.2121\tval_Loss 0.6503\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [73][100]\tLoss 0.3409\tval_Loss 0.6354\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [74][100]\tLoss 0.2263\tval_Loss 0.6268\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [75][100]\tLoss 0.2216\tval_Loss 0.6260\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [76][100]\tLoss 0.8480\tval_Loss 0.6212\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [77][100]\tLoss 0.1770\tval_Loss 0.6179\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [78][100]\tLoss 0.1530\tval_Loss 0.6227\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [79][100]\tLoss 0.1722\tval_Loss 0.6235\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [80][100]\tLoss 0.2282\tval_Loss 0.6123\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [81][100]\tLoss 0.3155\tval_Loss 0.5912\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [82][100]\tLoss 0.2950\tval_Loss 0.5822\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [83][100]\tLoss 0.2473\tval_Loss 0.5935\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [84][100]\tLoss 0.2836\tval_Loss 0.6191\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [85][100]\tLoss 0.1742\tval_Loss 0.6421\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [86][100]\tLoss 0.5033\tval_Loss 0.6494\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [87][100]\tLoss 0.1927\tval_Loss 0.6449\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [88][100]\tLoss 0.1852\tval_Loss 0.6422\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [89][100]\tLoss 0.7491\tval_Loss 0.6401\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [90][100]\tLoss 0.2481\tval_Loss 0.6348\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [91][100]\tLoss 0.3879\tval_Loss 0.6270\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [92][100]\tLoss 0.2454\tval_Loss 0.6166\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [93][100]\tLoss 0.2286\tval_Loss 0.6108\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [94][100]\tLoss 0.1720\tval_Loss 0.5963\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [95][100]\tLoss 0.4495\tval_Loss 0.5823\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [96][100]\tLoss 0.2654\tval_Loss 0.5831\n",
      "\n",
      "Current best val_loss: 0.5189\n",
      "Epoch: [97][100]\tLoss 0.1646\tval_Loss 0.5948\n",
      "\n",
      "Early stopping\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[3m        Test Results        \u001B[0m\n",
       "┏━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mMetrics \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mResults      \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│\u001B[36m \u001B[0m\u001B[36mtest_mae\u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m94083424.0000\u001B[0m\u001B[35m \u001B[0m│\n",
       "│\u001B[36m \u001B[0m\u001B[36mtest_r2 \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m0.8106       \u001B[0m\u001B[35m \u001B[0m│\n",
       "└──────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">        Test Results        </span>\n",
       "┏━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics  </span>┃<span style=\"font-weight: bold\"> Results       </span>┃\n",
       "┡━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_mae </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 94083424.0000 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_r2  </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 0.8106        </span>│\n",
       "└──────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_mae 94083424.0000\n",
      "test_r2 0.8106\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
